{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 neurons in input layer,\n",
    "3 neurons in output layer,\n",
    "2 nodes in 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pandas.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',names=['sepal.length','sepal.width','petal.length','petal.width','species'])\n",
    "X = iris.loc[:, iris.columns != 'species']\n",
    "X =(X-X.min())/(X.max()-X.min())\n",
    "y = pandas.get_dummies(iris['species'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(t) = \\frac{1}{1 + e^{-t}}$$\n",
    "$\\hat{y} = f(f(XW^{(1)} +  B^{(1)})W^{(2)}+B^{(2)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  X_train.shape[0]\n",
    "input_layer_size = X_train.shape[1]\n",
    "output_layer_size = 3\n",
    "hidden_layer_size = 2\n",
    "\n",
    "def sigmoid(z):\n",
    "    return(1/(1 + np.exp(z)))\n",
    "           \n",
    "def sigmoid_prime(z):\n",
    "    return(np.exp(-z)/(1 + np.exp(z))**2)\n",
    "\n",
    "def cost(y,y_pred):\n",
    "    return(0.5 * np.sum(np.square(np.matrix(y) - np.matrix(y_pred))))\n",
    "\n",
    "def initialize_weights(rows, columns):\n",
    "    W = []\n",
    "    for row in range(rows):\n",
    "        W.append(np.random.uniform(low = -.5, high = .5, size = columns))\n",
    "    return(np.matrix(W))\n",
    "\n",
    "W1 = initialize_weights(input_layer_size, hidden_layer_size)\n",
    "W2 = initialize_weights(hidden_layer_size, output_layer_size)\n",
    "b1 = np.random.uniform(size = hidden_layer_size) \n",
    "B1 = np.matrix([b1 for i in range(batch_size)])\n",
    "b2 = np.random.uniform(size = output_layer_size) \n",
    "B2 = np.matrix([b2 for i in range(batch_size)])\n",
    "\n",
    "def forward_prop(X, y, W1, B1, W2, B2):\n",
    "    Z2 = X.dot(W1)\n",
    "    A2 = sigmoid(Z2 + B1)\n",
    "    Z3 = A2.dot(W2)\n",
    "    y_pred = sigmoid(Z3 + B2)\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.59917508643306"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forward_prop(X_train, y_train, W1, B1, W2, B2)\n",
    "cost(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost Function:\n",
    "$$J = 0.5 \\sum (y - \\hat{y})^2 = 0.5 \\sum (y - f(f(XW^{(1)} +  B^{(1)})W^{(2)}+B^{(2)}))^2$$\n",
    "\n",
    "Gradient of Cost Function:\n",
    "$$\\frac{\\partial J }{\\partial W^{(1)}} = X^{T}-(y - \\hat{y})^2  *f'(z^{(3)}+B^{(1)})*W^{(2)T}f'(z^{(3)})$$\n",
    "$$\\frac{\\partial J }{\\partial W^{(2)}} = a^{(2)}-(y - \\hat{y})^2  *f'(z^{(3)}+B^{(1)})$$\n",
    "$$\\frac{\\partial J }{\\partial B^{(1)}} = a^{(2)}-(y - \\hat{y})^2  *f'(z^{(3)}+B^{(1)})$$\n",
    "$$\\frac{\\partial J }{\\partial B^{(2)}} = a^{(2)}-(y - \\hat{y})^2  *f'(z^{(3)}+B^{(1)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.29847891527977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(X, y, W1, B1, W2, B2, rate, iters):\n",
    "    y = np.matrix(y)\n",
    "    for i in range(iters):\n",
    "        Z2 = X.dot(W1)\n",
    "        A2 = sigmoid(Z2 + B1)\n",
    "        Z3 = A2.dot(W2)\n",
    "        y_pred = sigmoid(Z3 + B2)\n",
    "        cost(y, y_pred)\n",
    "        delta3 = -(y - y_pred).multiply(sigmoid_prime(Z3 + B2))\n",
    "        delta2 = delta3.dot(W2.transpose()).multiply(sigmoid_prime(Z2 + B1))\n",
    "        djdb2 = np.ones(X.shape[0]).dot(delta3)\n",
    "        djdw2 = A2.transpose().dot(delta3)\n",
    "        djdb1 = np.ones(X.shape[0]).dot(delta2)\n",
    "        djdw1 = X.transpose().dot(delta2)\n",
    "        W1 = W1 - djdw1 * rate\n",
    "        B1 = B1 - djdb1.transpose() * rate\n",
    "        W2 = W2 - djdw2 * rate\n",
    "        B2 = B2 - djdb2.transpose() * rate\n",
    "    return(W1, B1, W2, B2)\n",
    "\n",
    "W1 = initialize_weights(input_layer_size, hidden_layer_size)\n",
    "W2 = initialize_weights(hidden_layer_size, output_layer_size)\n",
    "b1 = np.random.uniform(size = hidden_layer_size) \n",
    "B1 = np.matrix([b1 for i in range(batch_size)])\n",
    "b2 = np.random.uniform(size = output_layer_size) \n",
    "B2 = np.matrix([b2 for i in range(batch_size)])\n",
    "\n",
    "W1, B1, W2, B2 = train_model(X_train, y_train ,W1, B1, W2, B2, 0.01, 8)\n",
    "y_pred = forward_prop(X_train, y_train, W1, B1, W2, B2)\n",
    "cost(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.insightsbot.com/tensorflow-tutorial-iris-classification-with-sgd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.loc[:, iris.columns != 'species']\n",
    "X =(X-X.min())/(X.max()-X.min())\n",
    "y = np.matrix(pandas.get_dummies(iris['species']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.10\n",
    "training_epochs = 100\n",
    "\n",
    "n_hidden_1 = 3\n",
    "n_hidden_2 = 3\n",
    "n_input = X_train.shape[1]\n",
    "n_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(\"float\", shape=[None, n_input])\n",
    "y = tf.compat.v1.placeholder(\"float\", shape=[None, n_classes])\n",
    "\n",
    "weights = {\n",
    "  'h1': tf.Variable(tf.random.normal([n_input, n_hidden_1])),\n",
    "  'h2': tf.Variable(tf.random.normal([n_hidden_1, n_hidden_2])),\n",
    "  'out': tf.Variable(tf.random.normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "  'b1': tf.Variable(tf.random.normal([n_hidden_1])),\n",
    "  'b2': tf.Variable(tf.random.normal([n_hidden_2])),\n",
    "  'out': tf.Variable(tf.random.normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Forward Propagation step\n",
    "def forward_propagation(x):\n",
    "    # Hidden layer1\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "#     out_layer = tf.matmul(layer_1, weights['out']) + biases['out'] \n",
    "\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out'] \n",
    "    return out_layer\n",
    "yhat = forward_propagation(X)\n",
    "ypredict = tf.argmax(input=yhat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "cost = tf.reduce_mean(input_tensor=tf.nn.softmax_cross_entropy_with_logits(labels=tf.stop_gradient(y), logits=yhat))\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 100, train accuracy = 32.42%, test accuracy = 39.11%\n",
      "Time taken: 0:00:08.605695\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "with tf.compat.v1.Session() as sesh:\n",
    "    sesh.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(len(X_train)):\n",
    "            summary = sesh.run(train_op, feed_dict={X: X_train[i: i + 1], y: y_train[i: i + 1]})\n",
    "        train_accuracy = np.mean(np.argmax(y_train, axis=1) == sesh.run(ypredict, feed_dict={X: X_train, y: y_train}))\n",
    "        test_accuracy  = np.mean(np.argmax(y_test, axis=1) == sesh.run(ypredict, feed_dict={X: X_test, y: y_test}))\n",
    "    sesh.close()\n",
    "print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\" % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "print(\"Time taken:\", datetime.now() - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
